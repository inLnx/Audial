<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audial - Audio recorder</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .record-button {
            transition: all 0.2s ease-in-out;
        }
        .record-button.recording {
            background-color: #ef4444;
        }
        .record-button.recording:hover {
            background-color: #dc2626;
        }
        #transcriptionDisplay {
            min-height: 50px;
            padding: 10px;
            background-color: #f3f4f6;
            border-radius: 8px;
            font-size: 1.125rem;
            color: #4b5563;
            text-align: center;
            overflow-y: auto;
            max-height: 150px;
        }
        .summary-loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #330446;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
            display: inline-block;
            vertical-align: middle;
            margin-left: 8px;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800 flex items-center justify-center min-h-screen">

    <div id="app-container" class="w-full max-w-4xl mx-auto bg-white shadow-2xl rounded-2xl overflow-hidden" style="height: 600px;">
        <div class="flex h-full">
            <div class="w-1/3 bg-gray-50 border-r border-gray-200 p-6 flex flex-col">
                <h2 class="text-2xl font-bold mb-6 text-gray-700">Current session recordings</h2>
                <div id="recordingsList" class="space-y-4 overflow-y-auto flex-grow">
                </div>
            </div>

            <div class="w-2/3 flex flex-col items-center justify-between p-10">
                <div class="flex items-center space-x-2 mb-6">
                    <input type="checkbox" id="transcriptionToggle" class="form-checkbox h-5 w-5 text-blue-600 rounded-md">
                    <label for="transcriptionToggle" class="text-lg text-gray-700 select-none">Enable Live Transcription</label>
                </div>

                <div class="flex-grow flex items-center justify-center flex-col">
                    <div id="timer" class="text-8xl font-mono font-bold text-gray-800 mb-4">00:00</div>
                    <div id="transcriptionDisplay" class="w-full text-center text-lg text-gray-700 border border-gray-300 rounded-lg p-3 overflow-y-auto max-h-40">
                        <p class="text-gray-500">Transcription will appear here...</p>
                    </div>
                </div>
                
                <div class="flex-shrink-0 mt-8">
                    <button id="recordButton" class="record-button bg-gray-200 hover:bg-gray-300 text-gray-800 font-bold py-4 px-12 rounded-full shadow-lg focus:outline-none text-2xl">
                        Record
                    </button>
                </div>
            </div>
        </div>
    </div>

    <div id="errorModal" class="hidden fixed inset-0 bg-black bg-opacity-50 z-50 flex items-center justify-center">
        <div class="bg-white p-6 rounded-lg shadow-xl max-w-sm mx-auto">
            <h3 class="text-lg font-bold mb-4">Error</h3>
            <p id="errorMessage"></p>
            <button onclick="document.getElementById('errorModal').classList.add('hidden')" class="mt-4 bg-red-500 text-white font-bold py-2 px-4 rounded w-full">Close</button>
        </div>
    </div>

    <div id="summaryModal" class="hidden fixed inset-0 bg-black bg-opacity-50 z-50 flex items-center justify-center">
        <div class="bg-white p-6 rounded-lg shadow-xl max-w-lg w-full mx-auto">
            <h3 class="text-lg font-bold mb-4 flex items-center">
                Summary of Transcription
                <span id="summaryLoader" class="summary-loader hidden"></span>
            </h3>
            <p id="summaryContent" class="text-gray-700 max-h-80 overflow-y-auto"></p>
            <button onclick="document.getElementById('summaryModal').classList.add('hidden'); document.getElementById('summaryContent').textContent = '';" class="mt-4 bg-blue-500 text-white font-bold py-2 px-4 rounded w-full">Close</button>
        </div>
    </div>


    <script type="module">
        let mediaRecorder;
        let audioChunks = [];
        let timerInterval;
        let seconds = 0;
        let isRecording = false;
        let localRecordings = [];
        
        let recognition;
        let currentTranscription = '';
        let isTranscriptionEnabled = false;

        const recordButton = document.getElementById('recordButton');
        const timerDisplay = document.getElementById('timer');
        const recordingsList = document.getElementById('recordingsList');
        const errorModal = document.getElementById('errorModal');
        const errorMessage = document.getElementById('errorMessage');
        const transcriptionToggle = document.getElementById('transcriptionToggle');
        const transcriptionDisplay = document.getElementById('transcriptionDisplay');
        const summaryModal = document.getElementById('summaryModal');
        const summaryContent = document.getElementById('summaryContent');
        const summaryLoader = document.getElementById('summaryLoader');


        function formatTime(totalSeconds) {
            const minutes = Math.floor(totalSeconds / 60).toString().padStart(2, '0');
            const seconds = (totalSeconds % 60).toString().padStart(2, '0');
            return `${minutes}:${seconds}`;
        }

        function showError(message) {
            errorMessage.textContent = message;
            errorModal.classList.remove('hidden');
        }
        
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        function downloadRecording(dataUrl, filename) {
            const a = document.createElement('a');
            a.href = dataUrl;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
        }

        async function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                await startRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                
                audioChunks = [];
                seconds = 0;
                currentTranscription = '';
                transcriptionDisplay.textContent = 'Transcription will appear here...';

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    try {
                        const audioDataUrl = await blobToBase64(audioBlob);
                        saveRecordingLocally(audioDataUrl, currentTranscription);
                    } catch (error) {
                        console.error("Error processing recording:", error);
                        showError("Could not process the recording. Please try again.");
                    }
                    stream.getTracks().forEach(track => track.stop());

                    if (recognition && isTranscriptionEnabled) {
                        recognition.stop();
                    }
                };

                mediaRecorder.start();
                isRecording = true;
                recordButton.textContent = 'Stop';
                recordButton.classList.add('recording');
                timerInterval = setInterval(() => {
                    seconds++;
                    timerDisplay.textContent = formatTime(seconds);
                }, 1000);

                if (isTranscriptionEnabled) {
                    startTranscription(stream);
                }

            } catch (err) {
                console.error("Error accessing microphone:", err);
                showError("Microphone access was denied. Please allow microphone access in your browser settings to use the recorder (and transcription).");
                isRecording = false;
                if (recognition) {
                    recognition.stop();
                }
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                mediaRecorder.stop();
            }
            isRecording = false;
            recordButton.textContent = 'Record';
            recordButton.classList.remove('recording');
            clearInterval(timerInterval);
            timerDisplay.textContent = '00:00';
            if (recognition && isTranscriptionEnabled) {
                recognition.stop();
            }
        }

        function startTranscription(stream) {
            window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

            if (!window.SpeechRecognition) {
                showError("Your browser does not support transcription.");
                isTranscriptionEnabled = false;
                transcriptionToggle.checked = false;
                return;
            }

            recognition = new SpeechRecognition();
            recognition.interimResults = true;
            recognition.continuous = true;
            recognition.lang = 'en-US';

            recognition.onresult = event => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }
                currentTranscription = finalTranscript + interimTranscript;
                transcriptionDisplay.textContent = currentTranscription || 'Transcription will appear here...';
            };

            recognition.onerror = event => {
                console.error('Speech Recognition Error:', event.error);
                let message = `Transcription error: ${event.error}.`;
                if (event.error === 'not-allowed') {
                    message += " Microphone not detected";
                } else if (event.error === 'no-speech') {
                    message += " No speech detected.";
                } else if (event.error === 'network') {
                    message += "Transcription requires an internet connection.";
                }
                showError(message);
                if (recognition) {
                    recognition.stop();
                }
                if (isRecording) {
                    stopRecording();
                }
            };
            
            recognition.onend = () => {
                if (isRecording && isTranscriptionEnabled) {
                    console.log("Speech recognition ended, restarting...");
                    try {
                         recognition.start();
                    } catch (e) {
                        console.warn("Could not start speech recognition:", e);
                        showError("Could not start transcription.");
                    }
                } else {
                    console.log("Speech recognition stopped normally.");
                }
            };

            recognition.start();
            transcriptionDisplay.textContent = 'Listening...';
        }
// AI function
// Please delete API key and replace with own key if cloning
// Google Gemini API keys are free for up to 50 times per day
// Thanks
        async function summarizeTranscription(textToSummarize) {
            summaryModal.classList.remove('hidden');
            summaryContent.textContent = 'Generating summary...';
            summaryLoader.classList.remove('hidden');

            if (!textToSummarize || textToSummarize.trim() === '') {
                summaryContent.textContent = "No transcription to summarize.";
                summaryLoader.classList.add('hidden');
                return;
            }

            try {
                let chatHistory = [];
                chatHistory.push({ role: "user", parts: [{ text: `Please summarize the following audio transcription concisely:\n\n${textToSummarize}` }] });
                
                const payload = { contents: chatHistory };
                const apiKey = "AIzaSyC0iXmXyUU_rMXFLCF8T63_mUDIgzCl8Io";
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const summary = result.candidates[0].content.parts[0].text;
                    summaryContent.textContent = summary;
                } else {
                    summaryContent.textContent = "Could not generate summary. No content returned from API.";
                    console.error("Unexpected API response structure:", result);
                }
            } catch (error) {
                console.error("Error calling Gemini API:", error);
                summaryContent.textContent = `Error generating summary: ${error.message}. Please try again.`;
            } finally {
                summaryLoader.classList.add('hidden');
            }
        }

        function saveRecordingLocally(audioDataUrl, transcriptionText) {
            const recordingId = Date.now().toString();
            const newRecording = {
                id: recordingId,
                name: `Recording ${new Date().toLocaleTimeString()}`,
                timestamp: new Date().toISOString(),
                audioDataUrl: audioDataUrl,
                transcription: transcriptionText
            };
            localRecordings.push(newRecording);
            localRecordings.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
            renderRecordings(localRecordings);
        }
        
        function deleteRecordingLocally(id) {
            localRecordings = localRecordings.filter(rec => rec.id !== id);
            renderRecordings(localRecordings);
        }

        function renderRecordings(recordings) {
            recordingsList.innerHTML = '';
            if (recordings.length === 0) {
                recordingsList.innerHTML = `<p class="text-gray-500 text-center">No recordings yet for this session.</p>`;
                return;
            }
            recordings.forEach(rec => {
                if (!rec.audioDataUrl) return;

                const card = document.createElement('div');
                card.className = 'bg-white p-4 rounded-lg border border-gray-200 shadow-sm';

                const nameEl = document.createElement('p');
                nameEl.className = 'font-semibold text-gray-700 truncate';
                nameEl.textContent = rec.name;

                const dateEl = document.createElement('p');
                dateEl.className = 'text-sm text-gray-500 mb-2';
                dateEl.textContent = new Date(rec.timestamp).toLocaleDateString() + ' ' + new Date(rec.timestamp).toLocaleTimeString();
                
                const audioEl = document.createElement('audio');
                audioEl.controls = true;
                audioEl.src = rec.audioDataUrl;
                audioEl.className = 'w-full mt-3 mb-2';

                if (rec.transcription && rec.transcription.trim() !== '') {
                    const transcriptionEl = document.createElement('p');
                    transcriptionEl.className = 'text-sm text-gray-600 italic border-t border-gray-200 pt-2 mt-2';
                    transcriptionEl.textContent = `"${rec.transcription.trim()}"`;
                    card.appendChild(transcriptionEl);
                }

                const actionsDiv = document.createElement('div');
                actionsDiv.className = 'flex flex-col space-y-2 mt-2';

                if (rec.transcription && rec.transcription.trim() !== '') {
                    const summarizeBtn = document.createElement('button');
                    summarizeBtn.innerHTML = `
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-robot inline-block mr-1" viewBox="0 0 16 16">
                            <path d="M6 12.5a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1-.5-.5M.5 12V3a.5.5 0 0 1 .5-.5h13a.5.5 0 0 1 .5.5v9a.5.5 0 0 1-.5.5h-13a.5.5 0 0 1-.5-.5M3 8.5a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm5-1.5a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm2.5-.5h-1a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm-5.5 4a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm5-1a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm2.5 0h-1a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5z"/>
                        </svg>
                        Summarize Transcription ✨
                    `;
                    summarizeBtn.className = 'bg-purple-500 hover:bg-purple-600 text-white font-bold py-2 px-4 rounded-md shadow-sm text-sm';
                    summarizeBtn.onclick = () => summarizeTranscription(rec.transcription);
                    actionsDiv.appendChild(summarizeBtn);
                }

                const downloadBtn = document.createElement('button');
                downloadBtn.innerHTML = `
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-download inline-block mr-1" viewBox="0 0 16 16">
                        <path d="M.5 9.9a.5.5 0 0 1 .5.5v2.5a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-2.5a.5.5 0 0 1 1 0v2.5a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2v-2.5a.5.5 0 0 1 .5-.5"/>
                        <path d="M7.646 11.854a.5.5 0 0 0 .708 0l3-3a.5.5 0 0 0-.708-.708L8.5 10.293V1.5a.5.5 0 0 0-1 0v8.793L5.354 8.146a.5.5 0 1 0-.708.708z"/>
                    </svg>
                    Download
                `;
                downloadBtn.className = 'text-blue-600 hover:text-blue-800 text-sm font-semibold py-1 px-2 rounded-md';
                downloadBtn.onclick = () => {
                    const filename = `recording-${new Date().toISOString().replace(/:/g, '-')}.webm`;
                    downloadRecording(rec.audioDataUrl, filename);
                };
                
                const deleteBtn = document.createElement('button');
                deleteBtn.innerHTML = `
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-trash inline-block" viewBox="0 0 16 16">
                        <path d="M5.5 5.5A.5.5 0 0 1 6 6v6a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m2.5 0a.5.5 0 0 1 .5.5v6a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m3 .5a.5.5 0 0 0-1 0v6a.5.5 0 0 0 1 0z"/>
                        <path d="M14.5 3a1 1 0 0 1-1 1H13v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V4h-.5a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1H6a1 1 0 0 1 1-1h2a1 1 0 0 1 1 1h3.5a1 1 0 0 1 1 1zM4.118 4 4 4.059V13a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V4.059L11.882 4zM2.5 3h11V2h-11z"/>
                    </svg>
                `;
                deleteBtn.className = 'text-red-500 hover:text-red-700 py-1 px-2 rounded-md';
                deleteBtn.onclick = () => deleteRecordingLocally(rec.id);
                
                actionsDiv.appendChild(downloadBtn);
                actionsDiv.appendChild(deleteBtn);

                card.appendChild(nameEl);
                card.appendChild(dateEl);
                card.appendChild(audioEl);
                card.appendChild(actionsDiv);

                recordingsList.appendChild(card);
            });
        }

        function initializeApp() {
            renderRecordings(localRecordings);

            transcriptionToggle.addEventListener('change', () => {
                isTranscriptionEnabled = transcriptionToggle.checked;
                if (isTranscriptionEnabled && !isRecording) {
                    transcriptionDisplay.textContent = 'Listening will begin when recording starts...';
                } else if (!isTranscriptionEnabled && !isRecording) {
                     transcriptionDisplay.textContent = 'Transcription will appear here...';
                }
            });
            isTranscriptionEnabled = transcriptionToggle.checked;
        }

        recordButton.addEventListener('click', toggleRecording);
        
        window.onload = initializeApp;

    </script>
</body>
</html>
