<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audial - Advanced Voice Recorder</title>
    <!-- Tailwind CSS CDN for utility-first styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Google Fonts for 'Inter' typeface -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        /* Custom CSS for 'Inter' font family */
        body {
            font-family: 'Inter', sans-serif;
        }

        /* Transition for menu buttons (though not directly used in this version's HTML) */
        .menu-button {
            transition: background-color 0.4s ease-out, transform 0.1s ease-out;
        }

        /* Transition for the record button */
        .record-button {
            transition: background-color 0.2s ease-in-out, transform 0.1s ease-out;
        }

        /* Styles for record button when recording */
        .record-button.recording {
            background-color: #d64545; /* Red color when recording */
            box-shadow: 0 0 15px rgba(239, 68, 68, 0.5); /* Subtle glow effect */
        }

        /* Hover styles for record button when recording */
        .record-button.recording:hover {
            background-color: #2e0503; /* Darker red on hover */
            transform: scale(0.98); /* Slight shrink effect on hover */
        }

        /* Styles for the transcription display area */
        #transcriptionDisplay {
            min-height: 60px;
            padding: 15px;
            background-color: #f3f4f6; /* Light gray background */
            border-radius: 12px; /* Rounded corners */
            font-size: 1.125rem; /* Text size */
            color: #4b5563; /* Dark gray text color */
            text-align: center;
            overflow-y: auto; /* Enable vertical scrolling if content overflows */
            max-height: 180px; /* Maximum height before scrolling */
            line-height: 1.6; /* Line height for better readability */
            border: 0.5px solid #d1d5db; /* Light border */
        }


        /* Custom styles for the summary loader spinner */
        .summary-loader {
            border: 4px solid #f3f3f3; /* Light gray border */
            border-top: 4px solid #6b21a8; /* Purple top border for spinner effect */
            border-radius: 50%; /* Makes it a circle */
            width: 28px; /* Spinner size */
            height: 28px;
            animation: spin 2s linear infinite; /* Spin animation */
            display: inline-block;
            vertical-align: middle;
            margin-left: 10px;
        }

        /* Keyframe animation for the spinner */
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        /* Box shadow for the main app container */
        #app-container {
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
        }

        /* Styles for the transcription toggle checkbox when checked */
        .form-checkbox:checked {
            background-color: #b13696; /* Purple background */
            border-color: #2563eb; /* Blue border */
        }
        /* Focus styles for the transcription toggle checkbox */
        .form-checkbox:focus {
            box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.5); /* Blue glow on focus */
            outline: none;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800 flex items-center justify-center min-h-screen p-4 sm:p-6">
    <!-- Main application container -->
    <div id="app-container" class="relative w-full max-w-4xl mx-auto bg-white shadow-xl rounded-xl overflow-hidden" style="min-height: 600px; max-height: 80vh;">
        <!-- "More" button for navigation (top right) -->
        <div class="absolute top-4 right-4 z-10">
            <a href="more.html" class="inline-block">
                <button class="bg-gray-100 hover:bg-gray-200 text-gray-700 font-semibold py-2 px-4 rounded-full shadow-sm text-sm transition-all duration-200 ease-in-out hover:scale-105">
                    ð“ƒ‘
                </button>
            </a>
        </div>

        <!-- Main Content Area: Flex container for panels -->
        <!-- This container handles switching between vertical (mobile) and horizontal (desktop) layouts -->
        <div class="flex h-full flex-col md:flex-row">
            <!-- Left Panel: Recordings List -->
            <!-- On mobile, hidden by default. Will be shown full-width when "Your Recordings" button is clicked. -->
            <!-- On desktop (md:), it's a 1/3 width flex column. -->
            <div id="recordingsPanel" class="w-full md:w-1/3 bg-gray-50 border-b md:border-b-0 md:border-r border-gray-200 p-6 flex-col hidden md:flex">
                <h2 class="text-xl font-bold mb-5 text-gray-700">Your Recordings</h2>
                <div id="recordingsList" class="space-y-4 overflow-y-auto flex-grow pr-2">
                    <!-- Recordings will be dynamically loaded here by JavaScript -->
                </div>
                <!-- Button to go back to recorder view (visible only on mobile when this panel is active) -->
                <button id="backToRecorderButton" class="mt-6 bg-purple-600 hover:bg-purple-700 text-white font-bold py-3 px-6 rounded-lg w-full transition-colors duration-200 hidden">Back to Recorder</button>
            </div>

            <!-- Right Panel: Recording Controls -->
            <!-- On mobile, shown full-width by default. Will be hidden when "Your Recordings" button is clicked. -->
            <!-- On desktop (md:), it's a 2/3 width flex column. -->
            <div id="recorderPanel" class="w-full md:w-2/3 flex flex-col items-center justify-between p-8 sm:p-10">
                <!-- Button to show recordings (visible only on mobile, when this panel is active) -->
                <button id="showRecordingsButton" class="md:hidden bg-gray-200 hover:bg-gray-300 text-gray-700 font-semibold py-2 px-4 rounded-full shadow-sm text-sm transition-all duration-200 ease-in-out mb-4">
                    Your Recordings
                </button>
                <!-- Toggle for live transcription -->
                <div class="flex items-center space-x-3 mb-8">
                    <input type="checkbox" id="transcriptionToggle" class="form-checkbox h-5 w-5 text-blue-500 rounded-md cursor-pointer">
                    <label for="transcriptionToggle" class="text-lg text-gray-700 select-none cursor-pointer">Enable Live Transcription</label>
                </div>

                <!-- Timer and transcription display -->
                <div class="flex-grow flex items-center justify-center flex-col w-full px-4">
                    <div id="timer" class="text-7xl lg:text-8xl font-mono font-extrabold text-gray-900 mb-6 tracking-tight">00:00</div>
                    <div id="transcriptionDisplay" class="w-full text-center text-base text-gray-600 border border-gray-300 rounded-lg p-3 overflow-y-auto max-h-40 shadow-inner">
                        <p class="text-black-400">Audial</p>
                    </div>
                </div>

                <!-- Record button -->
                <div class="flex-shrink-0 mt-10">
                    <button id="recordButton" class="record-button bg-blue-500 hover:bg-blue-600 text-white font-bold py-4 px-16 rounded-full shadow-lg focus:outline-none focus:ring-4 focus:ring-blue-300 text-2xl uppercase tracking-wide">
                        Start Recording
                    </button>
                </div>
            </div>
        </div>
    </div>

    <!-- Error Modal -->
    <div id="errorModal" class="hidden fixed inset-0 bg-black bg-opacity-60 z-50 flex items-center justify-center p-4">
        <div class="bg-white p-7 rounded-lg shadow-2xl max-w-sm w-full mx-auto text-center">
            <h3 class="text-xl font-bold mb-4 text-red-600">Something went wrong.</h3>
            <p id="errorMessage" class="text-gray-700 mb-5"></p>
            <button onclick="document.getElementById('errorModal').classList.add('hidden')" class="mt-4 bg-red-500 hover:bg-red-600 text-white font-bold py-3 px-6 rounded-lg w-full transition-colors duration-200">Got It</button>
        </div>
    </div>

    <!-- Summary Modal -->
    <div id="summaryModal" class="hidden fixed inset-0 bg-black bg-opacity-60 z-50 flex items-center justify-center p-4">
        <div class="bg-white p-7 rounded-lg shadow-2xl max-w-lg w-full mx-auto">
            <h3 class="text-xl font-bold mb-4 flex items-center text-gray-800">
                AI Generated Summary
                <span id="summaryLoader" class="summary-loader hidden"></span>
            </h3>
            <div id="summaryContent" class="text-gray-700 max-h-80 overflow-y-auto border border-gray-200 p-4 rounded-md bg-gray-50 leading-relaxed text-base"></div>
            <button onclick="document.getElementById('summaryModal').classList.add('hidden'); document.getElementById('summaryContent').textContent = '';" class="mt-6 bg-purple-600 hover:bg-purple-700 text-white font-bold py-3 px-6 rounded-lg w-full transition-colors duration-200">Close Summary</button>
        </div>
    </div>

    <script type="module">
        // Global variables for recording and transcription
        let mediaRecorder;
        let audioChunks = [];
        let timerInterval;
        let seconds = 0;
        let isRecording = false;
        let sessionRecordings = []; // Stores recordings for the current session

        let speechRecognition;
        let currentLiveTranscription = ''; // Stores the live transcription text
        let isTranscriptionEnabled = false; // Flag to check if transcription is enabled

        // DOM element references
        const recordButton = document.getElementById('recordButton');
        const timerDisplay = document.getElementById('timer');
        const recordingsList = document.getElementById('recordingsList');
        const errorModal = document.getElementById('errorModal');
        const errorMessage = document.getElementById('errorMessage');
        const transcriptionToggle = document.getElementById('transcriptionToggle');
        const transcriptionDisplay = document.getElementById('transcriptionDisplay');
        const summaryModal = document.getElementById('summaryModal');
        const summaryContent = document.getElementById('summaryContent');
        const summaryLoader = document.getElementById('summaryLoader');

        // New DOM element references for responsive view management
        const recordingsPanel = document.getElementById('recordingsPanel');
        const recorderPanel = document.getElementById('recorderPanel');
        const showRecordingsButton = document.getElementById('showRecordingsButton');
        const backToRecorderButton = document.getElementById('backToRecorderButton');


        /**
         * Formats total seconds into a MM:SS string.
         * @param {number} totalSeconds - The total number of seconds.
         * @returns {string} Formatted time string (e.g., "00:00", "01:23").
         */
        function formatTime(totalSeconds) {
            const minutes = Math.floor(totalSeconds / 60).toString().padStart(2, '0');
            const secs = (totalSeconds % 60).toString().padStart(2, '0');
            return `${minutes}:${secs}`;
        }

        /**
         * Displays an error message in a modal.
         * @param {string} message - The error message to display.
         */
        function displayError(message) {
            errorMessage.textContent = message;
            errorModal.classList.remove('hidden');
        }

        /**
         * Converts a Blob object to a Base64 data URL.
         * @param {Blob} blob - The Blob to convert.
         * @returns {Promise<string>} A promise that resolves with the Base64 data URL.
         */
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        /**
         * Triggers a download of a given data URL as a file.
         * @param {string} dataUrl - The data URL to download.
         * @param {string} filename - The desired filename for the download.
         */
        function triggerDownload(dataUrl, filename) {
            const a = document.createElement('a');
            a.href = dataUrl;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
        }

        /**
         * Toggles the recording state (start or stop).
         */
        async function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                await startRecording();
            }
        }

        /**
         * Initiates the audio recording and live transcription (if enabled).
         */
        async function startRecording() {
            try {
                // Request microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                audioChunks = [];
                seconds = 0;
                currentLiveTranscription = '';
                transcriptionDisplay.textContent = 'Audial'; // Reset transcription display

                // Collect audio data chunks
                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                // Handle recording stop event
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    try {
                        const audioDataUrl = await blobToBase64(audioBlob);
                        saveRecordingToSession(audioDataUrl, currentLiveTranscription); // Save the recording
                    } catch (error) {
                        console.error("Failed to process recording:", error);
                        displayError("Couldn't save your recording. Please try again!");
                    } finally {
                        // Stop all media tracks (microphone)
                        stream.getTracks().forEach(track => track.stop());
                        // Stop speech recognition if active
                        if (speechRecognition && isTranscriptionEnabled) {
                            speechRecognition.stop();
                        }
                    }
                };

                // Start the media recorder
                mediaRecorder.start();
                isRecording = true;
                recordButton.textContent = 'â¹'; // Change button text to stop icon
                recordButton.classList.add('recording');

                // Start the timer
                timerInterval = setInterval(() => {
                    seconds++;
                    timerDisplay.textContent = formatTime(seconds);
                }, 1000);

                // Start live transcription if enabled
                if (isTranscriptionEnabled) {
                    startLiveTranscription();
                }

            } catch (err) {
                // Handle microphone access errors
                console.error("Microphone access error:", err);
                if (err.name === "NotAllowedError" || err.name === "PermissionDeniedError") {
                    displayError("We need microphone access to record! Please allow it in your browser settings.");
                } else if (err.name === "NotFoundError") {
                    displayError("No microphone found.");
                } else {
                    displayError("An unexpected error occurred accessing your microphone. (" + err.message + ")");
                }
                isRecording = false; // Ensure recording state is false on error
                if (speechRecognition) {
                    speechRecognition.stop(); // Stop speech recognition in case of error
                }
            }
        }

        /**
         * Stops the audio recording and associated processes.
         */
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop(); // Stop the media recorder
            }
            isRecording = false;
            recordButton.textContent = 'â–¶'; // Change button text to play icon
            recordButton.classList.remove('recording');
            clearInterval(timerInterval); // Stop the timer
            timerDisplay.textContent = '00:00'; // Reset timer display
            if (speechRecognition && isTranscriptionEnabled) {
                speechRecognition.stop(); // Stop speech recognition
            }
        }

        /**
         * Initializes and starts the Web Speech API for live transcription.
         */
        function startLiveTranscription() {
            window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

            // Check for browser support
            if (!window.SpeechRecognition) {
                displayError("Your browser doesn't support live transcription. Try a Chromium or Safari browser.");
                transcriptionToggle.checked = false; // Uncheck the toggle if not supported
                return;
            }

            speechRecognition = new SpeechRecognition();
            speechRecognition.interimResults = true; // Get interim results for live display
            speechRecognition.continuous = true; // Keep listening even after pauses
            speechRecognition.lang = 'en-US'; // Set language

            // Handle speech recognition results
            speechRecognition.onresult = event => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' '; // Add final results
                    } else {
                        interimTranscript += transcript; // Add interim results
                    }
                }
                currentLiveTranscription = finalTranscript + interimTranscript;
                transcriptionDisplay.textContent = currentLiveTranscription || 'Still listening...'; // Update display
            };

            speechRecognition.onerror = event => {
                console.error('Speech Recognition Error:', event.error);
                let message = `Transcription error: "${event.error}".`;
                if (event.error === 'not-allowed') {
                    message = "Microphone blocked. Please ensure microphone access is granted for live transcription.";
                } else if (event.error === 'no-speech') {
                    message = "No speech detected. Please speak clearly into the microphone.";
                } else if (event.error === 'network') {
                    message = "Network error. Please check your internet connection.";
                }
                displayError(message);

                if (speechRecognition) {
                    speechRecognition.stop();
                }
                if (isRecording) {
                    stopRecording();
                }
            };

            speechRecognition.onend = () => {
                if (isRecording && isTranscriptionEnabled) {
                    console.log("Speech recognition stopped, attempting to restart...");
                    try {
                        speechRecognition.start(); 
                        } catch (e) {
                        console.warn("Failed to restart speech recognition:", e);
                        displayError("Couldn't restart live transcription. Please try recording again.");
                    }
                } else {
                    console.log("Speech recognition gracefully stopped.");
                    transcriptionDisplay.textContent = currentLiveTranscription || 'Transcription ended.';
                }
            };

            speechRecognition.start(); 
            transcriptionDisplay.textContent = 'Listening for your voice...';
        }

        
        async function getTranscriptionSummary(textToSummarize) {
            summaryModal.classList.remove('hidden');
            summaryContent.textContent = 'Generating...';
            summaryLoader.classList.remove('hidden');

            if (!textToSummarize || textToSummarize.trim() === '') {
                summaryContent.textContent = "There's no text to summarize for this recording. Try a longer one!";
                summaryLoader.classList.add('hidden');
                return;
            }

            try {
                let chatHistory = [];
                chatHistory.push({ role: "user", parts: [{ text: `Please provide a concise summary of the following audio transcription. Focus on key points and main ideas:\n\n"${textToSummarize}"` }] });

                const payload = { contents: chatHistory };
                const apiKey = "AIzaSyC0iXmXyUU_rMXFLCF8T63_mUDIgzCl8Io"; 
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const errorDetails = await response.json();
                    throw new Error(`API call failed: ${response.status} - ${errorDetails.error?.message || 'Unknown error'}`);
                }

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const summary = result.candidates[0].content.parts[0].text;
                    summaryContent.textContent = summary;
                } else {
                    summaryContent.textContent = "The AI couldn't generate a summary at this time. Please try again.";
                    console.error("Unexpected or empty API response:", result);
                }
            } catch (error) {
                console.error("Error calling Gemini API:", error);
                summaryContent.textContent = `Couldn't generate summary: ${error.message}.`;
            } finally {
                summaryLoader.classList.add('hidden');
            }
        }

        function saveRecordingToSession(audioDataUrl, transcriptionText) {
            const recordingId = `rec-${Date.now()}`;
            const newRecording = {
                id: recordingId,
                name: `Voice Memo ${new Date().toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit', hour12: true })}`,
                timestamp: new Date().toISOString(),
                audioDataUrl: audioDataUrl,
                transcription: transcriptionText.trim()
            };
            sessionRecordings.unshift(newRecording); 
            renderRecordingsList(sessionRecordings); 
            if (window.innerWidth < 768 && recordingsPanel.classList.contains('flex')) {
            }
        }

  
        function deleteRecordingFromSession(id) {
            if (!confirm('Are you sure you want to delete this recording?')) {
                return;
            }
            sessionRecordings = sessionRecordings.filter(rec => rec.id !== id);
            renderRecordingsList(sessionRecordings); 
        }

      
        function renderRecordingsList(recordings) {
            recordingsList.innerHTML = '';
            if (recordings.length === 0) {
                recordingsList.innerHTML = `<p class="text-gray-500 text-center py-4">No recordings yet.</p>`;
                return;
            }
            recordings.forEach(rec => {
                if (!rec.audioDataUrl) return;

                const card = document.createElement('div');
                card.className = 'bg-white p-4 rounded-lg border border-gray-200 shadow-sm transition-all duration-150 hover:shadow-md';

                const nameEl = document.createElement('p');
                nameEl.className = 'font-semibold text-gray-800 truncate text-base mb-1';
                nameEl.textContent = rec.name;

                const dateEl = document.createElement('p');
                dateEl.className = 'text-xs text-gray-500 mb-3';
                dateEl.textContent = new Date(rec.timestamp).toLocaleString();

                const audioEl = document.createElement('audio');
                audioEl.controls = true;
                audioEl.src = rec.audioDataUrl;
                audioEl.className = 'w-full my-3 rounded-md';

                const actionsDiv = document.createElement('div');
                actionsDiv.className = 'flex flex-wrap gap-2 mt-4';

                
                if (rec.transcription && rec.transcription !== '') {
                    const transcriptionEl = document.createElement('p');
                    transcriptionEl.className = 'text-sm text-gray-600 italic border-t border-gray-100 pt-3 mt-3 max-h-24 overflow-y-auto';
                    transcriptionEl.textContent = `"${rec.transcription}"`;
                    card.appendChild(transcriptionEl);

                    const summarizeBtn = document.createElement('button');
                    summarizeBtn.innerHTML = `
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-robot inline-block mr-1 -mt-0.5" viewBox="0 0 16 16">
                            <path d="M6 12.5a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1-.5-.5M.5 12V3a.5.5 0 0 1 .5-.5h13a.5.5 0 0 1 .5.5v9a.5.5 0 0 1-.5.5h-13a.5.5 0 0 1-.5-.5M3 8.5a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm5-1.5a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm2.5-.5h-1a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm-5.5 4a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm5-1a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5zm2.5 0h-1a.5.5 0 0 0-.5.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5z"/>
                        </svg>
                        Summarize
                    `;
                    summarizeBtn.className = 'bg-purple-500 hover:bg-purple-600 text-white font-bold py-2 px-3 rounded-md shadow-sm text-sm flex items-center justify-center transition-colors duration-200';
                    summarizeBtn.onclick = () => getTranscriptionSummary(rec.transcription);
                    actionsDiv.appendChild(summarizeBtn);
                }

                const downloadBtn = document.createElement('button');
                downloadBtn.innerHTML = `
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-download inline-block mr-1 -mt-0.5" viewBox="0 0 16 16">
                        <path d="M.5 9.9a.5.5 0 0 1 .5.5v2.5a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-2.5a.5.5 0 0 1 1 0v2.5a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2v-2.5a.5.5 0 0 1 .5-.5"/>
                        <path d="M7.646 11.854a.5.5 0 0 0 .708 0l3-3a.5.5 0 0 0-.708-.708L8.5 10.293V1.5a.5.5 0 0 0-1 0v8.793L5.354 8.146a.5.5 0 1 0-.708.708z"/>
                    </svg>
                    Download
                `;
                downloadBtn.className = 'text-blue-600 hover:text-blue-800 text-sm font-semibold py-2 px-3 rounded-md flex items-center justify-center transition-colors duration-200';
                downloadBtn.onclick = () => {
                    const filename = `Recording-${new Date().toISOString().replace(/[:.]/g, '-')}.webm`;
                    triggerDownload(rec.audioDataUrl, filename);
                };

                const deleteBtn = document.createElement('button');
                deleteBtn.innerHTML = `
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-trash inline-block mr-1 -mt-0.5" viewBox="0 0 16 16">
                        <path d="M5.5 5.5A.5.5 0 0 1 6 6v6a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m2.5 0a.5.5 0 0 1 .5.5v6a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m3 .5a.5.5 0 0 0-1 0v6a.5.5 0 0 0 1 0z"/>
                        <path d="M14.5 3a1 1 0 0 1-1 1H13v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V4h-.5a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1H6a1 1 0 0 1 1-1h2a1 1 0 0 1 1 1h3.5a1 1 0 0 1 1 1zM4.118 4 4 4.059V13a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V4.059L11.882 4zM2.5 3h11V2h-11z"/>
                    </svg>
                    Delete
                `;
                deleteBtn.className = 'text-red-500 hover:text-red-700 py-2 px-3 rounded-md flex items-center justify-center transition-colors duration-200';
                deleteBtn.onclick = () => deleteRecordingFromSession(rec.id);

                actionsDiv.appendChild(downloadBtn);
                actionsDiv.appendChild(deleteBtn);

                card.appendChild(nameEl);
                card.appendChild(dateEl);
                card.appendChild(audioEl);
                card.appendChild(actionsDiv);

                recordingsList.appendChild(card);
            });
        }

        function isPWADisplayMode() {
            return window.matchMedia('(display-mode: standalone)').matches;
        }

        function isMobileAspectRatio() {
            return (window.innerWidth / window.innerHeight) < (4 / 3);
        }

    
        function managePanelVisibility(view) {
            const useMobileUI = isMobileAspectRatio() || isPWADisplayMode();

            if (!useMobileUI) {
                recordingsPanel.classList.remove('hidden');
                recordingsPanel.classList.add('flex'); 
                recorderPanel.classList.remove('hidden');
                recorderPanel.classList.add('flex'); 
                showRecordingsButton.classList.add('hidden');
                backToRecorderButton.classList.add('hidden');
            } else {
                if (view === 'recorder') {
                    recorderPanel.classList.remove('hidden');
                    recorderPanel.classList.add('flex');
                    recordingsPanel.classList.add('hidden');
                    recordingsPanel.classList.remove('flex');
                    showRecordingsButton.classList.remove('hidden'); 
                    backToRecorderButton.classList.add('hidden');
                } else if (view === 'recordings') {
                    recorderPanel.classList.add('hidden');
                    recorderPanel.classList.remove('flex');
                    recordingsPanel.classList.remove('hidden');
                    recordingsPanel.classList.add('flex');
                    showRecordingsButton.classList.add('hidden'); 
                    backToRecorderButton.classList.remove('hidden'); 
                }
            }
        }


        function initAudialApp() {
            renderRecordingsList(sessionRecordings); 

            transcriptionToggle.addEventListener('change', () => {
                isTranscriptionEnabled = transcriptionToggle.checked;
                if (isTranscriptionEnabled && !isRecording) {
                    transcriptionDisplay.textContent = 'Start recording to transcribe';
                } else if (!isTranscriptionEnabled && !isRecording) {
                     transcriptionDisplay.textContent = 'Audial';
                }
                if (isRecording) {
                    if (isTranscriptionEnabled && (!speechRecognition || speechRecognition.state === 'inactive')) {
                        startLiveTranscription();
                    } else if (!isTranscriptionEnabled && speechRecognition && speechRecognition.state === 'recording') {
                        speechRecognition.stop();
                    }
                }
            });

            isTranscriptionEnabled = transcriptionToggle.checked;

       managePanelVisibility('recorder');

            showRecordingsButton.addEventListener('click', () => managePanelVisibility('recordings'));
            backToRecorderButton.addEventListener('click', () => managePanelVisibility('recorder'));

            window.addEventListener('resize', () => {
                const currentMobileView = recorderPanel.classList.contains('flex') ? 'recorder' : 'recordings';
                managePanelVisibility(currentMobileView);
            });
        }

        recordButton.addEventListener('click', toggleRecording);

        window.addEventListener('load', initAudialApp);
    </script>
</body>
</html>
